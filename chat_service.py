import asyncio
import json
import logging
from typing import Optional, List, Dict,AsyncGenerator
from openai.types.chat import ChatCompletionChunk
from openai import OpenAI
from mcp_service import MCPService
from config_loader import load_mcp_config

logger = logging.getLogger(__name__)

class ChatService:
    def __init__(self, env_config: dict, use_mcp: bool = False, mcp_config_path: Optional[str] = None):
        self.api_key = env_config["API_KEY"]
        self.base_url = env_config["BASE_URL"]
        self.model_name = env_config["MODEL"]
        self.max_tokens = env_config["MAX_TOKENS"]
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
        
        # MCP æœåŠ¡æ§åˆ¶
        self.use_mcp = use_mcp
        self.mcp_config_path: Optional[str] = mcp_config_path
        self.mcp_services: Dict[str, MCPService] = {}

        # æ‰“å°é…ç½®ä¿¡æ¯
        print("=== èŠå¤©æœåŠ¡é…ç½® ===")
        print(f"APIå¯†é’¥: {'å·²è®¾ç½®' if self.api_key else 'æœªè®¾ç½®'}")
        print(f"åŸºç¡€URL: {self.base_url}")
        print(f"æ¨¡å‹åç§°: {self.model_name}")
        print(f"æœ€å¤§ä»¤ç‰Œæ•°: {self.max_tokens}")
        print(f"MCPæœåŠ¡: {'å¯ç”¨' if self.use_mcp else 'ç¦ç”¨'}")
        if self.use_mcp and mcp_config_path:
            print(f"MCPé…ç½®æ–‡ä»¶: {mcp_config_path}")
        print("==================")
        
        logger.info("èŠå¤©æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    async def test_api_connection(self) -> bool:
        """æµ‹è¯• LLM API è¿æ¥"""
        logger.info("æµ‹è¯• LLM API è¿æ¥")
        print("æ­£åœ¨æµ‹è¯•APIè¿æ¥...")
        try:
            response = await asyncio.to_thread(
                self.client.chat.completions.create,
                model=self.model_name,
                max_tokens=10,
                messages=[{"role": "user", "content": "Hi"}]
            )
            print("âœ“ APIè¿æ¥æˆåŠŸ!")
            logger.info(f"APIæµ‹è¯•æˆåŠŸï¼Œå“åº”: {response.choices[0].message.content}")
            return True
        except Exception as e:
            error_msg = str(e)
            print(f"âœ— APIè¿æ¥å¤±è´¥: {error_msg}")
            logger.error(f"APIè¿æ¥æµ‹è¯•å¤±è´¥: {error_msg}")
            return False

    async def connect_mcp(self) -> bool:
        """è¿æ¥ MCP æœåŠ¡é…ç½®ä¸­å®šä¹‰çš„æ‰€æœ‰æœåŠ¡"""
        if not self.use_mcp or not self.mcp_config_path:
            return False

        try:
            # åŠ è½½é…ç½®ï¼Œç›´æ¥è·å– StdioServerParameters å­—å…¸
            servers_params = load_mcp_config(self.mcp_config_path)
            
            if not servers_params:
                logger.warning("é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„ MCP æœåŠ¡")
                return False

            self.mcp_services.clear()

            for name, stdio_params in servers_params.items():
                try:
                    service = MCPService(stdio_params)
                    if await service.connect():
                        self.mcp_services[name] = service
                        logger.info(f"æˆåŠŸè¿æ¥ MCP æœåŠ¡ [{name}]")
                    else:
                        logger.warning(f"MCP æœåŠ¡ [{name}] è¿æ¥å¤±è´¥")
                except Exception as e:
                    logger.error(f"è¿æ¥ MCP æœåŠ¡ [{name}] å¤±è´¥: {str(e)}")

            return len(self.mcp_services) > 0

        except Exception as e:
            logger.error(f"åŠ è½½ MCP é…ç½®å¤±è´¥: {str(e)}")
            return False

    async def toggle_mcp(self, enable: bool, config_path="./mcp_config.json") -> None:
        """åŠ¨æ€å¯ç”¨æˆ–ç¦ç”¨ MCP æœåŠ¡"""
        logger.info(f"åˆ‡æ¢MCPæœåŠ¡çŠ¶æ€: {'å¯ç”¨' if enable else 'ç¦ç”¨'}")
        if enable:
            if not config_path:
                print("âŒ è¯·æä¾›MCPé…ç½®æ–‡ä»¶è·¯å¾„")
                logger.error("æœªæä¾›MCPé…ç½®æ–‡ä»¶è·¯å¾„")
                return
            self.mcp_config_path = config_path
            self.use_mcp = True
            success = await self.connect_mcp()
            if success:
                print("âœ“ MCPæœåŠ¡å·²å¯ç”¨")
            else:
                print("âŒ MCPæœåŠ¡å¯ç”¨å¤±è´¥")
                self.use_mcp = False
                self.mcp_services.clear()
        else:
            for svc in self.mcp_services.values():
                await svc.disconnect()
            self.mcp_services.clear()
            self.use_mcp = False
            print("âœ“ MCPæœåŠ¡å·²ç¦ç”¨")
        logger.info(f"MCPæœåŠ¡çŠ¶æ€: {'å¯ç”¨' if self.use_mcp else 'ç¦ç”¨'}")

    async def call_tool(self, tool_name: str, tool_args: Dict) -> str:
        """åœ¨æ‰€æœ‰MCPæœåŠ¡ä¸­æŸ¥æ‰¾å¹¶è°ƒç”¨æ”¯æŒè¯¥å·¥å…·çš„æœåŠ¡"""
        for name, svc in self.mcp_services.items():
            if svc.is_connected:
                tools = await svc.list_tools()
                if any(t["function"]["name"] == tool_name for t in tools):
                    logger.info(f"ä½¿ç”¨æœåŠ¡ [{name}] è°ƒç”¨å·¥å…· [{tool_name}]")
                    return await svc.call_tool(tool_name, tool_args)
        raise RuntimeError(f"æœªæ‰¾åˆ°æ”¯æŒå·¥å…· {tool_name} çš„ MCP æœåŠ¡")

    async def process_query(self, query: str) -> str:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
        logger.info(f"å¤„ç†æŸ¥è¯¢: {query[:50]}...")
        messages = [{"role": "user", "content": query}]
        available_tools = []

        if self.use_mcp:
            for svc in self.mcp_services.values():
                tools = await svc.list_tools()
                available_tools.extend(tools)

        try:
            response = await asyncio.to_thread(
                self.client.chat.completions.create,
                model=self.model_name,
                max_tokens=self.max_tokens,
                messages=messages,
                tools=available_tools if available_tools else None
            )
            message = response.choices[0].message
            result_parts = []

            if message.content:
                result_parts.append(message.content)
                logger.info(f"æ”¶åˆ°AIå›å¤: {message.content[:100]}...")

            if message.tool_calls and self.use_mcp:
                logger.info(f"æ‰§è¡Œ {len(message.tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
                for tool_call in message.tool_calls:
                    tool_name = tool_call.function.name
                    try:
                        tool_args = json.loads(tool_call.function.arguments)
                    except json.JSONDecodeError:
                        logger.error(f"å·¥å…·å‚æ•°JSONè§£æå¤±è´¥: {tool_call.function.arguments}")
                        continue

                    result_parts.append(f"\n[æ­£åœ¨è°ƒç”¨å·¥å…·: {tool_name}]")
                    try:
                        tool_content = await self.call_tool(tool_name, tool_args)
                        messages.append({
                            "role": "assistant",
                            "content": message.content,
                            "tool_calls": [{
                                "id": tool_call.id,
                                "type": "function",
                                "function": {
                                    "name": tool_name,
                                    "arguments": tool_call.function.arguments
                                }
                            }]
                        })
                        messages.append({
                            "role": "tool",
                            "content": tool_content,
                            "tool_call_id": tool_call.id
                        })
                        final_response = await asyncio.to_thread(
                            self.client.chat.completions.create,
                            model=self.model_name,
                            max_tokens=self.max_tokens,
                            messages=messages
                        )
                        final_content = final_response.choices[0].message.content
                        if final_content:
                            result_parts.append(f"\n{final_content}")
                    except Exception as e:
                        error_msg = f"å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {str(e)}"
                        logger.error(error_msg)
                        result_parts.append(f"\n[é”™è¯¯: {error_msg}]")

            final_result = "".join(result_parts)
            logger.info("æŸ¥è¯¢å¤„ç†å®Œæˆ")
            return final_result
        except Exception as e:
            error_msg = f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            raise RuntimeError(error_msg)

    async def chat_loop(self):
        """è¿è¡Œäº¤äº’å¼èŠå¤©å¾ªç¯"""
        print("\nğŸ¤– èŠå¤©æœåŠ¡å·²å¯åŠ¨!")
        print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("è¾“å…¥ '!mcp on ' å¯ç”¨MCPæœåŠ¡")
        print("è¾“å…¥ '!mcp off' ç¦ç”¨MCPæœåŠ¡")
        print("-" * 50)

        while True:
            try:
                query = input("\nğŸ’¬ æ‚¨çš„é—®é¢˜: ").strip()

                if query.lower() in ['quit', 'exit']:
                    print("ğŸ‘‹ å†è§!")
                    break

                if not query:
                    continue

                if query.startswith('!mcp'):
                    parts = query.split()
                    if len(parts) >= 2:
                        if parts[1].lower() == 'on':
                            await self.toggle_mcp(True)
                        elif parts[1].lower() == 'off':
                            await self.toggle_mcp(False)
                        else:
                            print("âŒ æ— æ•ˆçš„MCPå‘½ä»¤ã€‚ç¤ºä¾‹: !mcp on æˆ– !mcp off")
                    continue

                print("\nğŸ”„ æ­£åœ¨å¤„ç†æ‚¨çš„é—®é¢˜...")
                response = await self.process_query(query)
                print(f"\nğŸ¤– å›ç­”:\n{response}")
                print("-" * 50)

                logger.info("ç”¨æˆ·æŸ¥è¯¢å¤„ç†å®Œæˆ")

            except KeyboardInterrupt:
                print("\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ï¼Œå†è§!")
                break
            except Exception as e:
                error_msg = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
                print(f"\nâŒ {error_msg}")
                logger.error(error_msg)
                
    async def stream_message(self, message: str, history: List[str]) -> AsyncGenerator[str, None]:
        """
        æµå¼è¾“å‡ºç”¨æˆ·æ¶ˆæ¯çš„å›å¤å†…å®¹ï¼Œç”¨äº WebSocket åœºæ™¯ã€‚
        """
        logger.info(f"å¼€å§‹æµå¼å¤„ç†æ¶ˆæ¯: {message[:50]}...")
        messages = []
        for i in range(0, len(history), 2):
            messages.append({"role": "user", "content": history[i]})
            if i + 1 < len(history):
                messages.append({"role": "assistant", "content": history[i + 1]})
        messages.append({"role": "user", "content": message})

        try:
            # åˆ›å»ºæµå¼å“åº”
            response = await asyncio.to_thread(
                lambda: self.client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    stream=True,
                    max_tokens=self.max_tokens
                )
            )

            for chunk in response:
                if isinstance(chunk, ChatCompletionChunk):
                    delta = chunk.choices[0].delta
                    content = delta.content or ""
                    if content:
                        yield content
        except Exception as e:
            logger.error(f"æµå¼æ¶ˆæ¯å¤„ç†å¤±è´¥: {str(e)}")
            raise

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("å¼€å§‹æ¸…ç†èŠå¤©æœåŠ¡èµ„æº")
        for svc in self.mcp_services.values():
            await svc.disconnect()
        logger.info("èŠå¤©æœåŠ¡èµ„æºæ¸…ç†å®Œæˆ")
